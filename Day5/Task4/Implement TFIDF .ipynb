{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e47f4c-4fe3-429f-a05c-59ecc1ca834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538531a0-36f6-4e08-8575-810826df7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"IPL_Match_Highlights_Commentary.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7c81f3-97db-4b76-a6a2-a1c4218460d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant column\n",
    "text_data = df['Commentary'].dropna().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed47dfd-c269-48be-942f-95d68fe1fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing: Tokenization and Removing Special Characters\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n",
    "    words = text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b304fe-38e3-4315-9ad6-b3ef080d409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute Term Frequency (TF)\n",
    "def compute_tf(corpus):\n",
    "    tf_values = []\n",
    "    for doc in corpus:\n",
    "        word_count = Counter(doc)\n",
    "        total_words = len(doc)\n",
    "        tf_values.append({word: count / total_words for word, count in word_count.items()})\n",
    "    return tf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d25678bb-7245-44f1-8dbd-7ce7f1c18097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Inverse Document Frequency (IDF)\n",
    "def compute_idf(corpus):\n",
    "    num_docs = len(corpus)\n",
    "    word_set = set(word for doc in corpus for word in doc)\n",
    "    idf_values = {}\n",
    "    for word in word_set:\n",
    "        containing_docs = sum(1 for doc in corpus if word in doc)\n",
    "        idf_values[word] = np.log((num_docs + 1) / (containing_docs + 1)) + 1\n",
    "    return idf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b617f3c5-a502-449f-827f-34c940b0a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TF-IDF\n",
    "def compute_tfidf(tf_values, idf_values):\n",
    "    tfidf_values = []\n",
    "    for tf in tf_values:\n",
    "        tfidf_values.append({word: tf[word] * idf_values[word] for word in tf})\n",
    "    return tfidf_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4855549-16ea-40b2-81d2-e5a72e0404bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "processed_corpus = text_data.apply(preprocess_text).tolist()\n",
    "\n",
    "# Compute TF, IDF, and TF-IDF\n",
    "tf_values = compute_tf(processed_corpus)\n",
    "idf_values = compute_idf(processed_corpus)\n",
    "tfidf_values = compute_tfidf(tf_values, idf_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1feeb799-276e-4b82-b7c1-8b8a15afa996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF values (computed from scratch):\n",
      "      nehra        to   mandeep      four     first  boundary       for  \\\n",
      "0  0.159658  0.050000  0.406122  0.043215  0.097068    0.0846  0.046455   \n",
      "1  0.255452  0.080000  0.216598  0.034572  0.077654    0.0000  0.000000   \n",
      "2  0.000000  0.071429  0.000000  0.041157  0.000000    0.0000  0.000000   \n",
      "3  0.364932  0.028571  0.000000  0.049388  0.000000    0.0000  0.000000   \n",
      "4  0.206010  0.064516  0.000000  0.055761  0.000000    0.0000  0.029971   \n",
      "\n",
      "        and       rcb      full  ...  uhoh  latent  wrath  microsix  whodve  \\\n",
      "0  0.136070  0.114943  0.072331  ...   0.0     0.0    0.0       0.0     0.0   \n",
      "1  0.043542  0.000000  0.000000  ...   0.0     0.0    0.0       0.0     0.0   \n",
      "2  0.051836  0.000000  0.000000  ...   0.0     0.0    0.0       0.0     0.0   \n",
      "3  0.031102  0.000000  0.082664  ...   0.0     0.0    0.0       0.0     0.0   \n",
      "4  0.035115  0.000000  0.000000  ...   0.0     0.0    0.0       0.0     0.0   \n",
      "\n",
      "   outunorthodox  paddlepulls  expresspacer  hastily  runnign  \n",
      "0            0.0          0.0           0.0      0.0      0.0  \n",
      "1            0.0          0.0           0.0      0.0      0.0  \n",
      "2            0.0          0.0           0.0      0.0      0.0  \n",
      "3            0.0          0.0           0.0      0.0      0.0  \n",
      "4            0.0          0.0           0.0      0.0      0.0  \n",
      "\n",
      "[5 rows x 11758 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame.from_records(tfidf_values).fillna(0)\n",
    "\n",
    "# Display TF-IDF values\n",
    "print(\"TF-IDF values (computed from scratch):\")\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529b98d7-8907-4161-a4d6-405438d9f29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF values using scikit-learn:\n",
      "   000   07   10  100  1000  100kph  100ks  100th  101  101kph  ...  zipping  \\\n",
      "0  0.0  0.0  0.0  0.0   0.0     0.0    0.0    0.0  0.0     0.0  ...      0.0   \n",
      "1  0.0  0.0  0.0  0.0   0.0     0.0    0.0    0.0  0.0     0.0  ...      0.0   \n",
      "2  0.0  0.0  0.0  0.0   0.0     0.0    0.0    0.0  0.0     0.0  ...      0.0   \n",
      "3  0.0  0.0  0.0  0.0   0.0     0.0    0.0    0.0  0.0     0.0  ...      0.0   \n",
      "4  0.0  0.0  0.0  0.0   0.0     0.0    0.0    0.0  0.0     0.0  ...      0.0   \n",
      "\n",
      "   zips  zone  zones  zoning  zoomed  zoomer  zooming  zooms  zoots  \n",
      "0   0.0   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "1   0.0   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "2   0.0   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "3   0.0   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "4   0.0   0.0    0.0     0.0     0.0     0.0      0.0    0.0    0.0  \n",
      "\n",
      "[5 rows x 9412 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verify using scikit-learn's TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "sklearn_tfidf = tfidf_vectorizer.fit_transform(text_data)\n",
    "sklearn_tfidf_df = pd.DataFrame(sklearn_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF values using scikit-learn:\")\n",
    "print(sklearn_tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144d697-20dd-4f75-9e3e-96cb300a11ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
